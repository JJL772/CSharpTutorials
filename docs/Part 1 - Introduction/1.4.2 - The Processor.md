
#The Processor
The processor is the core of the computer. It executes programs, carries out operations that it's told to do, manages memory and does a lot more important stuff. Without the processor, the computer would be a useless pile of components.

#What does it do?
As stated above, the processor's main goal is to perform operations that it's told to do. The processor handles operations like: execution of programs, memory management and communication between other components in the computer. This is just the tip of the iceberg, however, as there are many more functions the processor carries out.

#The anatomy of a processor
The processor contains numerous subsystems, but there's a few major ones. First of all, we have the CU, or control unit, which is basically the core of the core. It handles all operations fed to it via instructions. The processor also has the ALU, or arithmetic logic unit, which performs all arithmetic operations and most logical operations too. Finally, we have the MMU, or memory management unit, which handles memory-related tasks, such as allocating memory and storing addresses. Because I feel so cool writing this tutorial, and I want to feel very hip indeed, here's this table:

|Component|Function|
|:---------:|:--------:|
| CU (Control unit) | Controls the processor and stuff |
| ALU (Arithmetic Logic Unit) | Uses fancy logic to perform math operations |
| MMU (Memory Management Unit) | Performs memory related operations |

##Registers
In order for the processor to be told what to do, engineers needed to come up with a solution that would allow programmers to pass instructions to the processor as well as get results from the processor. The solution were registers. Registers are small on-chip storage devices which can store a small amount of information for the processor to use. These registers are pretty limited in number and are usually the width of the architecture, for example, on a 32-bit system, these registers would be 32bits wide. By passing data into these registers and sending signals to the processor, a programmer can instruct the processor to carry out a variety of operations. These registers can store any number of values that fit within their bounds, including memory addresses. Because this is a C# tutorial, I will not get into the specifics of how these work and how one can use them, but for reference, [here is a list of all the registers on an 8086 system.](http://www.eecg.toronto.edu/~amza/www.mindsec.com/files/x86regs.html)

#But How does it work?
The processor is a detailed and complex piece of precision-engineered equipment, with trillions of transistors, each of which are usually less than 40nm wide (usually less than 28nm on most modern computers). The smart computer architectects and other engineers work to design these devices in such a way that they are programmable using machine code. The way you tell a processor to do something on the low level side of things is by using instructions. Each processor implements what's known as an instruction set, or a set of instructions provided by a computer architecture. One of the most common computer architectures in 8086, which is abbreviated x86, and the 64bit version of this architecture is abbreviated x86-64 or just x64. Each architecture has a standard for which instructions should be implemented and what those instructions should do. Each of these instructions has a numeric code associated with it. When the processor is fed the memory address where these instructions are located, the processor will begin execution.

#Measuring Performance
Measuring the performance of a computer processor isn't really an easy task, there are a number of ways to measure it and, individually, these performance metrics are useless to an extend. To get a good estimate on computer performance we must combine multiple performance metrics into one.

##Clock Rate
The first measurement of processor performance is the clock rate. Each processor has an internal oscillator which determines its internal clock rate. (I won't get into how this works as it's relatively complicated) The speed of the oscillator is measured in Hz, traditionally, but in modern CPUs, it's often measured in GHz (1 billion hertz). The clock rate essentially determines how quickly instructions are to be executed, but, they don't always execute at that speed. Each operation the CPU performs will take a number of clock cycles to complete, for a simple instruction, this could be as little as 1 clock cycle, but for a more complex instruction, say a memory access instruction, this could take upwards of 100 clock cycles.

We have to keep in mind that a high clock cycle speed doesn't always mean "best performance". It's dependent on core count, optimization and other things too.

##Core count
The performance of a CPU is also heavily reliant on the number of cores the CPU has. Generally, the more the better, but this must be balanced out by clock speed and optimization.

Here's an example of a situation where core count is very important.
Let's say that I have two processors, CPU1 and CPU2. We're also going to pretend that we live in a magical world, where all instructions take 1 clock cycle to run and where everything is perfectly optimized. 
The specifications for CPU1 and CPU2 are as follows:

|CPU1|
|----|
| Clock Speed (GHz) | 4GHz |
| Core Count | 2 |

| CPU2 |
|------|
| Clock Speed (GHz) | 5GHz |
| Core Count | 1 |

Which one would run faster?
In our magical perfect world, CPU1 would run faster. Why? CPU1 is operating at 4GHz, and has 2 cores, both of which are operating at 4GHz. In total, if we distribute our instructions over each of the cores, we can get a *theoretical* execution rate of 8GHz. (4GHz * 2 cores = 8) Although CPU2 has a better clock rate per core, it only has 1 core. So, if we distribute the instructions over all cores, we will only get an effective execution rate of 5GHz.

##Optimization
There's not much to talk about here, except that a more optimized instruction set can execute faster. By providing shortcuts and faster instruction execution times, processors can execute as fast as or even faster than processors with better overall specifications, but worse optimization.

##FLOPS
I technically lied when I said "we must combine all metrics together to get the best measurement" as this is one of the best measurements of performance you can get for a processor. FLOPS stands for Floating Point Operations Per Second (Note: FL stands for float). This is a theoretical measure of the number of mathematical operations per second a processor can perform. Measurements like these are usually used in things like GPUs rather than CPUs, as GPUs are more based around math than CPUs are. In modern processing devices, FLOPS are usually measured in TFLOPS (Terra FLOPS or Trillion Floating Point Operations Per Second). To put that into perspective, the latest released GPU from Nvidia is expected to pull ~110 TFLOPS. FLOPS don't measure everything, however, it doesn't account for non-mathematical operation speed, like memory access and whatnot.


